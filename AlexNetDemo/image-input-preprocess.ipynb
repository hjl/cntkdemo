{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires numpy, scipy, pillow, cv2, os, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Image as IPyImage\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For now, let's assume there is a single flat directory of raw (unprocessed) source images.\n",
    "For each image, we will have at least the following to start:\n",
    "- original filename (as appearing in the input directory)\n",
    "- original file format, length, creation / modification date\n",
    "- original file image dimensions (w, h)\n",
    "additional information that may or may not be present:\n",
    "- pixel planes (1-4), pixel format (RGB, HSV, CMYK...), pixel depth (1-16)\n",
    "- for now, we will assume all images are encoded as JPEG, RGB, 8bpp\n",
    "    - some of these will actually be monochrome (grayscale) and/or tinted monochrome\n",
    "\n",
    "For each image, construct a standardized set of prepared input images for feature construction\n",
    "- 256 x 256 (cropped to 224 x 224 for convnet)\n",
    "- 128 x 128 for thumbnails\n",
    "- for non-square images, cropping/resizing policy?\n",
    "    - convnet pipeline will do crop/resize/flip/aspect \n",
    "\n",
    "For sufficiently large input images, construct normalized set of sub-images (independent of convnet preprocessing)\n",
    "- center region (50%) plus four quadrants (50%), standardized to same 256 x 256 (or 224 x 224)\n",
    "    - these are likely to contain partial views of intended subjects in scene\n",
    "    - only do this if minimum input dimension is (2 x 256) or larger\n",
    "\n",
    "For each prepared input image, construct a bookkeeping record (can go in database table, search index, etc)\n",
    "- original (raw) source image path/name, dimension, file info\n",
    "- input (prepared) source image path/name, dimension, file info (will be more than one for each raw source image)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SOURCE_IMAGE_DIRECTORY = r'E:\\local\\TestData\\training-images\\hjl'\n",
    "STANDARD_THUMBNAIL_DIRECTORY = r'E:\\local\\TestData\\training-images\\thumbnail'\n",
    "THUMBNAIL_SIZE = 128, 128\n",
    "STANDARD_IMAGE_DIM = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queueing E:\\local\\TestData\\training-images\\hjl\\9080540205_077ca98a05_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\8745890385_a4bf97cf70_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\6988939547_d734af8034_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\9498125419_6ccdc0575d_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\9575536980_ab788e76a9_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\14961861191_939396d3bd_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\26153910890_9d454af6e6_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\10487234964_75368e3ab5_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\9624735029_27dc504663_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\8827012370_ca7cf39ac0_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\25464585526_9df4ccef92_o.jpg\n",
      "queueing E:\\local\\TestData\\training-images\\hjl\\24842360564_cbc68dc8d0_o.jpg\n",
      "queued 12 items\n"
     ]
    }
   ],
   "source": [
    "raw_input_queue = []\n",
    "\n",
    "for dirname, dirnames, filenames in os.walk(SOURCE_IMAGE_DIRECTORY):\n",
    "    #print(dirname, dirnames, filenames)\n",
    "    # print path to all subdirectories first.\n",
    "#    for subdirname in dirnames:\n",
    "#        print(os.path.join(dirname, subdirname))\n",
    "\n",
    "    for filename in filenames:\n",
    "        full_raw_input_path = os.path.join(dirname, filename)\n",
    "        print('queueing', full_raw_input_path)\n",
    "        raw_input_queue.append(full_raw_input_path)\n",
    "\n",
    "print('queued', len(raw_input_queue), 'items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_item_record(item):\n",
    "    item_properties = dict()\n",
    "    item_properties['raw_size'] = os.path.getsize(item)\n",
    "    item_properties['raw_dirname'] = os.path.dirname(item)\n",
    "    item_properties['raw_filename'] = os.path.basename(item)\n",
    "    item_properties['raw_ctime'] = os.path.getctime(item)\n",
    "    item_properties['raw_fullpath'] = item\n",
    "\n",
    "    return item_properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_standardized_image(item):\n",
    "    image_properties = dict()\n",
    "    im = PILImage.open(item)\n",
    "    image_properties['width'] = im.width\n",
    "    image_properties['height'] = im.height\n",
    "    image_properties['pixel_format'] = im.mode\n",
    "    \n",
    "    im_thumb = im.copy()\n",
    "    im.thumb(THUMBNAIL_SIZE)\n",
    "    im_thumb_filename = Path(item).stem\n",
    "    im_thumb_filename = im_thumb_filename + '_thumb' + '.jpg'\n",
    "    im_thumb_path = os.path.join(STANDARD_THUMBNAIL_DIRECTORY, im_thumb_filename)\n",
    "    im_thumb.save(im_thumb_path, 'JPEG')\n",
    "    im_thumb.close()\n",
    "    \n",
    "    im_standard = im.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    im.close()\n",
    "    \n",
    "    \n",
    "    image_properties['thumbnail_path'] = im_thumb_path\n",
    "\n",
    "    return image_properties\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing E:\\local\\TestData\\training-images\\hjl\\9080540205_077ca98a05_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 854, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\9080540205_077ca98a05_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.04, 'raw_size': 493606, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\9080540205_077ca98a05_o.jpg', 'raw_filename': '9080540205_077ca98a05_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\8745890385_a4bf97cf70_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 853, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\8745890385_a4bf97cf70_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.11, 'raw_size': 996586, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\8745890385_a4bf97cf70_o.jpg', 'raw_filename': '8745890385_a4bf97cf70_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\6988939547_d734af8034_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1024, 'height': 683, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\6988939547_d734af8034_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.25, 'raw_size': 225564, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\6988939547_d734af8034_o.jpg', 'raw_filename': '6988939547_d734af8034_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\9498125419_6ccdc0575d_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 853, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\9498125419_6ccdc0575d_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.32, 'raw_size': 1001949, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\9498125419_6ccdc0575d_o.jpg', 'raw_filename': '9498125419_6ccdc0575d_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\9575536980_ab788e76a9_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 853, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\9575536980_ab788e76a9_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.47, 'raw_size': 434147, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\9575536980_ab788e76a9_o.jpg', 'raw_filename': '9575536980_ab788e76a9_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\14961861191_939396d3bd_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 960, 'height': 1280, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\14961861191_939396d3bd_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.57, 'raw_size': 761507, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\14961861191_939396d3bd_o.jpg', 'raw_filename': '14961861191_939396d3bd_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\26153910890_9d454af6e6_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 853, 'height': 1280, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\26153910890_9d454af6e6_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.76, 'raw_size': 599816, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\26153910890_9d454af6e6_o.jpg', 'raw_filename': '26153910890_9d454af6e6_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\10487234964_75368e3ab5_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 960, 'height': 1280, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\10487234964_75368e3ab5_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926567.86, 'raw_size': 767505, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\10487234964_75368e3ab5_o.jpg', 'raw_filename': '10487234964_75368e3ab5_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\9624735029_27dc504663_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 853, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\9624735029_27dc504663_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926568.03, 'raw_size': 660004, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\9624735029_27dc504663_o.jpg', 'raw_filename': '9624735029_27dc504663_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\8827012370_ca7cf39ac0_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 1280, 'height': 853, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\8827012370_ca7cf39ac0_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926568.15, 'raw_size': 612431, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\8827012370_ca7cf39ac0_o.jpg', 'raw_filename': '8827012370_ca7cf39ac0_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\25464585526_9df4ccef92_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 853, 'height': 1280, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\25464585526_9df4ccef92_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926568.23, 'raw_size': 618109, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\25464585526_9df4ccef92_o.jpg', 'raw_filename': '25464585526_9df4ccef92_o.jpg'}}\n",
      "processing E:\\local\\TestData\\training-images\\hjl\\24842360564_cbc68dc8d0_o.jpg\n",
      "{'source_image': {'pixel_format': 'RGB', 'width': 853, 'height': 1280, 'thumbnail_path': 'E:\\\\local\\\\TestData\\\\training-images\\\\thumbnail\\\\24842360564_cbc68dc8d0_o_thumb.jpg'}, 'source_file': {'raw_ctime': 1500926568.31, 'raw_size': 738039, 'raw_dirname': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl', 'raw_fullpath': 'E:\\\\local\\\\TestData\\\\training-images\\\\hjl\\\\24842360564_cbc68dc8d0_o.jpg', 'raw_filename': '24842360564_cbc68dc8d0_o.jpg'}}\n"
     ]
    }
   ],
   "source": [
    "for item in raw_input_queue:\n",
    "    print('processing', item)\n",
    "    item_info = dict()\n",
    "    item_info['source_file'] = make_item_record(item)\n",
    "    item_info['source_image'] = generate_standardized_image(item)\n",
    "#    print(make_item_record(item))\n",
    "#    print(generate_standardized_image(item))\n",
    "    print(item_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cntk35]",
   "language": "python",
   "name": "conda-env-cntk35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
